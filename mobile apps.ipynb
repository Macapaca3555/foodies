{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\maxza\\anaconda3\\envs\\Final_Project_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\maxza\\anaconda3\\envs\\Final_Project_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\maxza\\anaconda3\\envs\\Final_Project_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\maxza\\anaconda3\\envs\\Final_Project_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\maxza\\anaconda3\\envs\\Final_Project_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\maxza\\anaconda3\\envs\\Final_Project_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\maxza\\anaconda3\\envs\\Final_Project_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\maxza\\anaconda3\\envs\\Final_Project_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\maxza\\anaconda3\\envs\\Final_Project_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\maxza\\anaconda3\\envs\\Final_Project_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\maxza\\anaconda3\\envs\\Final_Project_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\maxza\\anaconda3\\envs\\Final_Project_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\maxza\\anaconda3\\envs\\Final_Project_env\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Train on 1532 samples, validate on 171 samples\n",
      "Epoch 1/100\n",
      "1532/1532 [==============================] - 2s 980us/sample - loss: 1.8403 - acc: 0.2350 - val_loss: 1.5478 - val_acc: 0.4035\n",
      "Epoch 2/100\n",
      "1532/1532 [==============================] - 1s 906us/sample - loss: 1.5869 - acc: 0.2735 - val_loss: 1.4715 - val_acc: 0.4386\n",
      "Epoch 3/100\n",
      "1532/1532 [==============================] - 1s 895us/sample - loss: 1.5122 - acc: 0.3610 - val_loss: 1.4001 - val_acc: 0.4737\n",
      "Epoch 4/100\n",
      "1532/1532 [==============================] - 1s 927us/sample - loss: 1.4213 - acc: 0.4014 - val_loss: 1.3445 - val_acc: 0.4620\n",
      "Epoch 5/100\n",
      "1532/1532 [==============================] - 1s 904us/sample - loss: 1.3800 - acc: 0.4510 - val_loss: 1.3181 - val_acc: 0.5205\n",
      "Epoch 6/100\n",
      "1532/1532 [==============================] - 1s 906us/sample - loss: 1.3226 - acc: 0.4843 - val_loss: 1.2699 - val_acc: 0.5322\n",
      "Epoch 7/100\n",
      "1532/1532 [==============================] - 1s 911us/sample - loss: 1.2948 - acc: 0.4980 - val_loss: 1.2852 - val_acc: 0.5029\n",
      "Epoch 8/100\n",
      "1532/1532 [==============================] - 1s 902us/sample - loss: 1.2707 - acc: 0.5033 - val_loss: 1.2372 - val_acc: 0.5263\n",
      "Epoch 9/100\n",
      "1532/1532 [==============================] - 1s 906us/sample - loss: 1.2386 - acc: 0.5242 - val_loss: 1.2741 - val_acc: 0.5263\n",
      "Epoch 10/100\n",
      "1532/1532 [==============================] - 1s 936us/sample - loss: 1.2174 - acc: 0.5366 - val_loss: 1.2311 - val_acc: 0.5205\n",
      "Epoch 11/100\n",
      "1532/1532 [==============================] - 1s 916us/sample - loss: 1.1760 - acc: 0.5424 - val_loss: 1.2176 - val_acc: 0.5146\n",
      "Epoch 12/100\n",
      "1532/1532 [==============================] - 1s 911us/sample - loss: 1.1521 - acc: 0.5640 - val_loss: 1.1965 - val_acc: 0.5322\n",
      "Epoch 13/100\n",
      "1532/1532 [==============================] - 1s 909us/sample - loss: 1.1611 - acc: 0.5692 - val_loss: 1.1255 - val_acc: 0.6082\n",
      "Epoch 14/100\n",
      "1532/1532 [==============================] - 1s 908us/sample - loss: 1.1129 - acc: 0.5725 - val_loss: 1.1189 - val_acc: 0.5965\n",
      "Epoch 15/100\n",
      "1532/1532 [==============================] - 1s 913us/sample - loss: 1.0728 - acc: 0.5803 - val_loss: 1.0791 - val_acc: 0.6140\n",
      "Epoch 16/100\n",
      "1532/1532 [==============================] - 1s 901us/sample - loss: 1.0342 - acc: 0.5999 - val_loss: 1.0632 - val_acc: 0.6140\n",
      "Epoch 17/100\n",
      "1532/1532 [==============================] - 1s 905us/sample - loss: 1.0156 - acc: 0.6070 - val_loss: 1.0513 - val_acc: 0.6023\n",
      "Epoch 18/100\n",
      "1532/1532 [==============================] - 1s 921us/sample - loss: 0.9704 - acc: 0.6266 - val_loss: 1.0514 - val_acc: 0.6433\n",
      "Epoch 19/100\n",
      "1532/1532 [==============================] - 1s 912us/sample - loss: 0.9209 - acc: 0.6443 - val_loss: 1.0764 - val_acc: 0.6257\n",
      "Epoch 20/100\n",
      "1532/1532 [==============================] - 1s 908us/sample - loss: 0.8617 - acc: 0.6756 - val_loss: 1.0956 - val_acc: 0.6023\n",
      "Epoch 21/100\n",
      "1532/1532 [==============================] - 1s 927us/sample - loss: 0.8285 - acc: 0.6978 - val_loss: 1.1252 - val_acc: 0.6491\n",
      "Epoch 22/100\n",
      "1532/1532 [==============================] - 1s 930us/sample - loss: 0.7630 - acc: 0.7206 - val_loss: 1.1713 - val_acc: 0.6082\n",
      "Epoch 23/100\n",
      "1532/1532 [==============================] - 1s 914us/sample - loss: 0.6777 - acc: 0.7533 - val_loss: 1.0981 - val_acc: 0.6784\n",
      "Epoch 24/100\n",
      "1532/1532 [==============================] - 1s 918us/sample - loss: 0.6269 - acc: 0.7604 - val_loss: 1.2763 - val_acc: 0.5906\n",
      "Epoch 25/100\n",
      "1532/1532 [==============================] - 1s 929us/sample - loss: 0.5508 - acc: 0.8009 - val_loss: 1.1797 - val_acc: 0.6374\n",
      "Epoch 26/100\n",
      "1532/1532 [==============================] - 1s 965us/sample - loss: 0.4711 - acc: 0.8303 - val_loss: 1.3485 - val_acc: 0.6257\n",
      "Epoch 27/100\n",
      "1532/1532 [==============================] - 1s 936us/sample - loss: 0.4031 - acc: 0.8655 - val_loss: 1.3370 - val_acc: 0.6550\n",
      "Epoch 28/100\n",
      "1532/1532 [==============================] - 1s 913us/sample - loss: 0.3764 - acc: 0.8721 - val_loss: 1.2873 - val_acc: 0.6550\n",
      "Epoch 29/100\n",
      "1532/1532 [==============================] - 1s 912us/sample - loss: 0.3166 - acc: 0.9008 - val_loss: 1.7097 - val_acc: 0.5906\n",
      "Epoch 30/100\n",
      "1532/1532 [==============================] - 1s 929us/sample - loss: 0.3016 - acc: 0.8995 - val_loss: 1.4262 - val_acc: 0.6316\n",
      "Epoch 31/100\n",
      "1532/1532 [==============================] - 1s 914us/sample - loss: 0.2156 - acc: 0.9328 - val_loss: 1.7663 - val_acc: 0.6199\n",
      "Epoch 32/100\n",
      "1532/1532 [==============================] - 1s 922us/sample - loss: 0.1982 - acc: 0.9302 - val_loss: 1.7462 - val_acc: 0.5965\n",
      "Epoch 33/100\n",
      "1532/1532 [==============================] - 1s 944us/sample - loss: 0.1669 - acc: 0.9497 - val_loss: 1.7764 - val_acc: 0.6374\n",
      "Epoch 34/100\n",
      "1532/1532 [==============================] - 1s 927us/sample - loss: 0.1238 - acc: 0.9634 - val_loss: 1.8135 - val_acc: 0.6316\n",
      "Epoch 35/100\n",
      "1532/1532 [==============================] - 1s 918us/sample - loss: 0.0971 - acc: 0.9700 - val_loss: 1.9625 - val_acc: 0.6082\n",
      "Epoch 36/100\n",
      "1532/1532 [==============================] - 1s 922us/sample - loss: 0.0810 - acc: 0.9785 - val_loss: 2.0420 - val_acc: 0.6023\n",
      "Epoch 37/100\n",
      "1532/1532 [==============================] - 1s 914us/sample - loss: 0.0580 - acc: 0.9856 - val_loss: 2.2986 - val_acc: 0.6316\n",
      "Epoch 38/100\n",
      "1532/1532 [==============================] - 1s 933us/sample - loss: 0.0547 - acc: 0.9837 - val_loss: 2.1899 - val_acc: 0.6374\n",
      "Epoch 39/100\n",
      "1532/1532 [==============================] - 1s 916us/sample - loss: 0.0501 - acc: 0.9863 - val_loss: 2.0565 - val_acc: 0.6082\n",
      "Epoch 40/100\n",
      "1532/1532 [==============================] - 1s 917us/sample - loss: 0.0428 - acc: 0.9902 - val_loss: 2.3409 - val_acc: 0.5731\n",
      "Epoch 41/100\n",
      "1532/1532 [==============================] - 1s 921us/sample - loss: 0.0632 - acc: 0.9824 - val_loss: 2.2633 - val_acc: 0.6082\n",
      "Epoch 42/100\n",
      "1532/1532 [==============================] - 1s 922us/sample - loss: 0.0479 - acc: 0.9869 - val_loss: 2.2690 - val_acc: 0.5848\n",
      "Epoch 43/100\n",
      "1532/1532 [==============================] - 1s 922us/sample - loss: 0.0627 - acc: 0.9869 - val_loss: 2.3306 - val_acc: 0.6257\n",
      "Epoch 44/100\n",
      "1532/1532 [==============================] - 1s 937us/sample - loss: 0.0413 - acc: 0.9889 - val_loss: 2.4737 - val_acc: 0.6023\n",
      "Epoch 45/100\n",
      "1532/1532 [==============================] - 1s 928us/sample - loss: 0.0266 - acc: 0.9928 - val_loss: 2.6532 - val_acc: 0.5789\n",
      "Epoch 46/100\n",
      "1532/1532 [==============================] - 1s 921us/sample - loss: 0.0439 - acc: 0.9869 - val_loss: 2.6141 - val_acc: 0.6140\n",
      "Epoch 47/100\n",
      "1532/1532 [==============================] - 1s 919us/sample - loss: 0.0330 - acc: 0.9948 - val_loss: 2.2873 - val_acc: 0.6023\n",
      "Epoch 48/100\n",
      "1532/1532 [==============================] - 1s 917us/sample - loss: 0.0282 - acc: 0.9922 - val_loss: 2.3847 - val_acc: 0.6199\n",
      "Epoch 49/100\n",
      "1532/1532 [==============================] - 1s 919us/sample - loss: 0.0140 - acc: 0.9961 - val_loss: 2.4874 - val_acc: 0.5906\n",
      "Epoch 50/100\n",
      "1532/1532 [==============================] - 1s 920us/sample - loss: 0.0182 - acc: 0.9948 - val_loss: 2.6826 - val_acc: 0.5848\n",
      "Epoch 51/100\n",
      "1532/1532 [==============================] - 1s 918us/sample - loss: 0.0222 - acc: 0.9954 - val_loss: 2.5727 - val_acc: 0.5789\n",
      "Epoch 52/100\n",
      "1532/1532 [==============================] - 1s 918us/sample - loss: 0.0171 - acc: 0.9961 - val_loss: 2.6314 - val_acc: 0.6316\n",
      "Epoch 53/100\n",
      "1532/1532 [==============================] - 1s 928us/sample - loss: 0.0161 - acc: 0.9967 - val_loss: 2.5311 - val_acc: 0.6023\n",
      "Epoch 54/100\n",
      "1532/1532 [==============================] - 1s 908us/sample - loss: 0.0187 - acc: 0.9954 - val_loss: 2.7413 - val_acc: 0.6199\n",
      "Epoch 55/100\n",
      "1532/1532 [==============================] - 1s 926us/sample - loss: 0.0143 - acc: 0.9974 - val_loss: 2.9553 - val_acc: 0.6433\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1532/1532 [==============================] - 1s 939us/sample - loss: 0.0124 - acc: 0.9948 - val_loss: 2.9109 - val_acc: 0.6316\n",
      "Epoch 57/100\n",
      "1532/1532 [==============================] - 1s 906us/sample - loss: 0.0121 - acc: 0.9967 - val_loss: 2.5421 - val_acc: 0.6199\n",
      "Epoch 58/100\n",
      "1532/1532 [==============================] - 1s 916us/sample - loss: 0.0164 - acc: 0.9961 - val_loss: 2.6092 - val_acc: 0.6082\n",
      "Epoch 59/100\n",
      "1532/1532 [==============================] - 1s 912us/sample - loss: 0.0184 - acc: 0.9954 - val_loss: 2.8069 - val_acc: 0.6316\n",
      "Epoch 60/100\n",
      "1532/1532 [==============================] - 1s 912us/sample - loss: 0.0306 - acc: 0.9896 - val_loss: 2.8050 - val_acc: 0.5497\n",
      "Epoch 61/100\n",
      "1532/1532 [==============================] - 1s 923us/sample - loss: 0.0332 - acc: 0.9915 - val_loss: 2.7071 - val_acc: 0.5906\n",
      "Epoch 62/100\n",
      "1532/1532 [==============================] - 1s 917us/sample - loss: 0.0241 - acc: 0.9935 - val_loss: 2.6787 - val_acc: 0.5731\n",
      "Epoch 63/100\n",
      "1532/1532 [==============================] - 1s 908us/sample - loss: 0.0447 - acc: 0.9850 - val_loss: 2.5145 - val_acc: 0.6316\n",
      "Epoch 64/100\n",
      "1532/1532 [==============================] - 1s 919us/sample - loss: 0.0338 - acc: 0.9915 - val_loss: 2.8479 - val_acc: 0.5965\n",
      "Epoch 65/100\n",
      "1532/1532 [==============================] - 1s 911us/sample - loss: 0.0211 - acc: 0.9961 - val_loss: 2.6697 - val_acc: 0.6257\n",
      "Epoch 66/100\n",
      "1532/1532 [==============================] - 1s 910us/sample - loss: 0.0158 - acc: 0.9961 - val_loss: 2.9994 - val_acc: 0.6023\n",
      "Epoch 67/100\n",
      "1532/1532 [==============================] - 1s 938us/sample - loss: 0.0195 - acc: 0.9941 - val_loss: 3.0701 - val_acc: 0.6140\n",
      "Epoch 68/100\n",
      "1532/1532 [==============================] - 1s 907us/sample - loss: 0.0277 - acc: 0.9922 - val_loss: 2.7377 - val_acc: 0.5497\n",
      "Epoch 69/100\n",
      "1532/1532 [==============================] - 1s 924us/sample - loss: 0.0245 - acc: 0.9915 - val_loss: 2.6011 - val_acc: 0.6316\n",
      "Epoch 70/100\n",
      "1532/1532 [==============================] - 1s 930us/sample - loss: 0.0212 - acc: 0.9922 - val_loss: 2.9540 - val_acc: 0.5673\n",
      "Epoch 71/100\n",
      "1532/1532 [==============================] - 1s 918us/sample - loss: 0.0143 - acc: 0.9948 - val_loss: 2.8605 - val_acc: 0.6023\n",
      "Epoch 72/100\n",
      "1532/1532 [==============================] - 1s 920us/sample - loss: 0.0316 - acc: 0.9922 - val_loss: 2.8815 - val_acc: 0.5789\n",
      "Epoch 73/100\n",
      "1532/1532 [==============================] - 1s 916us/sample - loss: 0.0213 - acc: 0.9935 - val_loss: 2.7790 - val_acc: 0.6023\n",
      "Epoch 74/100\n",
      "1532/1532 [==============================] - 1s 914us/sample - loss: 0.0193 - acc: 0.9961 - val_loss: 2.9844 - val_acc: 0.5906\n",
      "Epoch 75/100\n",
      "1532/1532 [==============================] - 1s 925us/sample - loss: 0.0147 - acc: 0.9935 - val_loss: 2.8112 - val_acc: 0.5848\n",
      "Epoch 76/100\n",
      "1532/1532 [==============================] - 1s 919us/sample - loss: 0.0199 - acc: 0.9922 - val_loss: 3.0026 - val_acc: 0.5673\n",
      "Epoch 77/100\n",
      "1532/1532 [==============================] - 1s 919us/sample - loss: 0.0238 - acc: 0.9948 - val_loss: 2.6234 - val_acc: 0.5965\n",
      "Epoch 78/100\n",
      "1532/1532 [==============================] - 1s 937us/sample - loss: 0.0164 - acc: 0.9941 - val_loss: 2.6764 - val_acc: 0.6140\n",
      "Epoch 79/100\n",
      "1532/1532 [==============================] - 1s 927us/sample - loss: 0.0200 - acc: 0.9935 - val_loss: 2.6937 - val_acc: 0.6140\n",
      "Epoch 80/100\n",
      "1532/1532 [==============================] - 1s 904us/sample - loss: 0.0159 - acc: 0.9961 - val_loss: 2.6793 - val_acc: 0.5673\n",
      "Epoch 81/100\n",
      "1532/1532 [==============================] - 1s 915us/sample - loss: 0.0173 - acc: 0.9935 - val_loss: 2.7542 - val_acc: 0.6140\n",
      "Epoch 82/100\n",
      "1532/1532 [==============================] - 1s 925us/sample - loss: 0.0148 - acc: 0.9974 - val_loss: 2.9543 - val_acc: 0.5906\n",
      "Epoch 83/100\n",
      "1532/1532 [==============================] - 1s 922us/sample - loss: 0.0095 - acc: 0.9980 - val_loss: 2.9664 - val_acc: 0.5906\n",
      "Epoch 84/100\n",
      "1532/1532 [==============================] - 1s 915us/sample - loss: 0.0099 - acc: 0.9987 - val_loss: 3.1147 - val_acc: 0.5848\n",
      "Epoch 85/100\n",
      "1532/1532 [==============================] - 1s 917us/sample - loss: 0.0103 - acc: 0.9967 - val_loss: 3.2093 - val_acc: 0.5965\n",
      "Epoch 86/100\n",
      "1532/1532 [==============================] - 1s 915us/sample - loss: 0.0147 - acc: 0.9948 - val_loss: 3.2816 - val_acc: 0.6023\n",
      "Epoch 87/100\n",
      "1532/1532 [==============================] - 1s 911us/sample - loss: 0.0045 - acc: 0.9987 - val_loss: 3.2476 - val_acc: 0.5906\n",
      "Epoch 88/100\n",
      "1532/1532 [==============================] - 1s 921us/sample - loss: 0.0088 - acc: 0.9974 - val_loss: 3.1902 - val_acc: 0.5731\n",
      "Epoch 89/100\n",
      "1532/1532 [==============================] - 1s 934us/sample - loss: 0.0049 - acc: 0.9987 - val_loss: 3.2399 - val_acc: 0.5848\n",
      "Epoch 90/100\n",
      "1532/1532 [==============================] - 1s 930us/sample - loss: 0.0023 - acc: 0.9993 - val_loss: 3.3531 - val_acc: 0.5731\n",
      "Epoch 91/100\n",
      "1532/1532 [==============================] - 1s 920us/sample - loss: 0.0057 - acc: 0.9987 - val_loss: 3.2914 - val_acc: 0.5673\n",
      "Epoch 92/100\n",
      "1532/1532 [==============================] - 1s 917us/sample - loss: 0.0079 - acc: 0.9987 - val_loss: 3.1930 - val_acc: 0.5848\n",
      "Epoch 93/100\n",
      "1532/1532 [==============================] - 1s 906us/sample - loss: 0.0132 - acc: 0.9974 - val_loss: 3.0872 - val_acc: 0.5789\n",
      "Epoch 94/100\n",
      "1532/1532 [==============================] - 1s 916us/sample - loss: 0.0086 - acc: 0.9967 - val_loss: 3.2397 - val_acc: 0.5731\n",
      "Epoch 95/100\n",
      "1532/1532 [==============================] - 1s 924us/sample - loss: 0.0070 - acc: 0.9987 - val_loss: 2.9538 - val_acc: 0.5848\n",
      "Epoch 96/100\n",
      "1532/1532 [==============================] - 1s 915us/sample - loss: 0.0057 - acc: 0.9980 - val_loss: 3.1297 - val_acc: 0.6082\n",
      "Epoch 97/100\n",
      "1532/1532 [==============================] - 1s 923us/sample - loss: 0.0108 - acc: 0.9967 - val_loss: 3.1764 - val_acc: 0.5848\n",
      "Epoch 98/100\n",
      "1532/1532 [==============================] - 1s 918us/sample - loss: 0.0041 - acc: 0.9987 - val_loss: 3.5485 - val_acc: 0.5848\n",
      "Epoch 99/100\n",
      "1532/1532 [==============================] - 1s 912us/sample - loss: 0.0093 - acc: 0.9967 - val_loss: 3.4701 - val_acc: 0.5789\n",
      "Epoch 100/100\n",
      "1532/1532 [==============================] - 1s 915us/sample - loss: 0.0055 - acc: 0.9987 - val_loss: 3.5193 - val_acc: 0.5731\n",
      "fat\n"
     ]
    }
   ],
   "source": [
    "import os,cv2,keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "Directory = r\"C:\\Users\\maxza\\Jupyter Programming Project 3rd year\\dataset\\food\"\n",
    "categories = ['dairy','fat','fruit and veg','protein','starch']\n",
    "\n",
    "    \n",
    "img_size = 50\n",
    "\n",
    "\n",
    "training_data = []\n",
    "def create_training_data():\n",
    "    for category in categories:\n",
    "        path = os.path.join(Directory, category)\n",
    "        class_num = categories.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img))\n",
    "                new_array = cv2.resize(img_array, (img_size, img_size))\n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "create_training_data()\n",
    "\n",
    "random.shuffle(training_data)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "X = np.array(X).reshape(-1, img_size, img_size, 3)\n",
    "X = X/255.0 \n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(50,50,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics = ['accuracy'])\n",
    "model.fit(X, y, batch_size = 256, epochs =100, validation_split = 0.1)\n",
    "img = cv2.imread('android.png')\n",
    "img = cv2.resize(img,(img_size,img_size))\n",
    "img = np.reshape(img,[1,img_size,img_size,3])\n",
    "results = model.predict_classes(img)\n",
    "if results == [0]:\n",
    "    print(\"dairy\")\n",
    "if results == [1]:\n",
    "    print(\"fat\")\n",
    "if results == [2]:\n",
    "    print(\"fruit and veg\")\n",
    "if results == [3]:\n",
    "    print(\"protein\")\n",
    "if results == [4]:\n",
    "    print(\"starch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Final_Project_env",
   "language": "python",
   "name": "final_project_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
